---
title: ""
output: html_notebook
---

## Script do Projeto Aprendizagem de Maquina


bibliotecas nescessarias 

```{r}

library(tidyverse)
library(ggplot2)
library(e1071)
library(stringr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(nnet)
library(partykit)
library(plyr)
library(corrplot)

```


### Carregando o banco de dados tratamentos dos dados

```{r warning=FALSE}

#Chamando banco de dados
mush <- read.table(file.choose(), header = T, sep = ",")
# Arquivo mushrooms em csv

#Renomeando cabeçalho
colnames(mush) <- c("classificacao", "formato_chapeu", "superficie_chapeu","cor_chapeu", "mancha", "odor",
"anexo_branquial", "espacamento_branquial", "tamanho_branquial",
"cor_branquial", "formato_caule", "raiz_caule", "superficie_caule_acima_anel", "superficie_caule_abaixo_anel",
"cor_caule_acima_anel", "cor_caule_abaixo_anel", "tipo_veu","cor_veu","numero_aneis","tipo_aneis","cor_esporos", "populacao","habitat")

View(mush)

```

O conjunto de dados contem variaveis categóricas, vamos organizar o banco de dados em variaveis factor e vamos renomar os leves(as classes) dos fatores. Note que como a variavel 17 ("tipo_veu") so tem uma classe vamos tirar ela do conjunto de dados pois não é significativa para o estudo.

```{r}
#Transformando todas variáveis em fator
mush <- mush %>% map_df(function(.x) as.factor(.x))

#Renomeando os levels
levels(mush$classificacao) <- c("comestivel", "venenoso")
levels(mush$formato_chapeu) <- c("sino", "conico", "plano", "botão", "baixo_relevo", "convexo")
levels(mush$superficie_chapeu) <- c("fibroso", "rachurado", "escamoso", "liso")
levels(mush$cor_chapeu) <- c("pele", "canela", "vermelho", "cinza", "marrom", "rosa", "verde", "roxo", "branco", "amarelo")
levels(mush$mancha) <- c("nao", "sim")
levels(mush$odor) <- c("amendoa", "creosotose", "falta", "anis", "mofado", "nenhum", "pungente", "picante", "duvidoso")
levels(mush$anexo_branquial) <- c("anexado", "livre")
levels(mush$espacamento_branquial) <- c("fechado", "coroa")
levels(mush$tamanho_branquial) <- c("ampla", "limitado")
levels(mush$cor_branquial) <- c("pele", "vermelho", "cinza", "chocolate", "preto", "marrom", "laranja", "rosa", "verde", "roxo", "branco", "amarelo")
levels(mush$formato_caule) <- c("ampliado", "afunilado")
levels(mush$raiz_caule) <- c("faltante", "bulbosa", "clube", "igual", "enraizado")
levels(mush$superficie_caule_acima_anel) <- c("fibroso", "sedosa", "liso", "escamosa")
levels(mush$superficie_caule_abaixo_anel) <- c("fibrosa", "sedosa", "lisa", "escamosa")
levels(mush$cor_caule_acima_anel) <- c("pele", "canela", "vermelho", "cinza", "marrom", "rosa", "verde", "roxo", "branco", "amarelo")
levels(mush$cor_caule_abaixo_anel) <- c("pele", "canela", "vermelho", "cinza", "marrom", "rosa", "verde", "roxo", "branco", "amarelo")

levels(mush$tipo_veu) <- c("parcial") ###
levels(mush$cor_veu) <- c("marrom", "laranja", "branco", "amarelo")
levels(mush$numero_aneis) <- c("nenhum", "um", "dois")
levels(mush$tipo_aneis) <- c("evanescente", "deslumbrante", "largo", "nenhum", "penso")
levels(mush$cor_esporos) <- c("pele", "chocolate", "preto", "marrom", "laranja", "verde", "roxo", "branco", "amarelo")
levels(mush$populacao) <- c("abundante", "agrupado", "numeroso", "espalhada", "varias", "solitaria")
levels(mush$habitat) <- c("madeira", "grama", "folhas", "campo", "caminhos", "urbano", "desperdicio")

#Retirando a variável "tipo_veu"
mush <- mush[,-17]
```

```{r warning=FALSE}
#Vusualização dos dados 
glimpse(mush)

# head(mush)
```

Com isso vemos que as variaveis do banco esta como factor e todas as classes estão renomeadas. Assim o banco esta pronto para as analise seguintes.
```{r}
attach(mush)
```

### Analise descirtiva

```{r}

#Relação entre superficie e cor chapeu para discriminar a classificacao  
ggplot(mush, aes(x = superficie_chapeu , y = cor_chapeu, col = classificacao)) + geom_jitter(alpha = 0.5) + scale_color_manual(breaks = c("comestivel", "venenoso"), values = c("green", "darkblue"))
```



A superficie fibrosa nos mostrou mais observcoes classificadas como comestivel, enquanto que a lisa mostra o oposto, salvo o caso de quando a cor do chapeu e verde ou roxa. A superficie escamosa com a cor do chapeu amarela tambem nos mostra total seguranca para consumo, enquanto que com o chapeu vermelho totalmente venenoso.

```{r}
ggplot(mush, aes(x = formato_chapeu, y = cor_chapeu, col = classificacao)) + geom_jitter(alpha = 0.5) + 
  scale_color_manual(breaks = c("comestivel", "venenoso"), 
                     values = c("green", "darkblue"))
```


O formato de sino se mostra mais seguro para consumo em relacao aos demais formatos, com excessão do no formato de baixo relevo sinaliza da mesma forma, contudo temos poucas observacoes do mesmo.

```{r}
ggplot(mush, aes(x = cor_branquial, y = cor_chapeu, col = classificacao)) +
  geom_jitter(alpha = 0.5) + 
  scale_color_manual(breaks = c("comestivel", "venenoso"), 
                     values = c("green", "darkblue"))
```


Procurar se ajusta angulo do xlab Vemos que para um cogumelo com cor do chapeu vermelho ele é comestivel quando a cor do branquio é vermelho, marrom, rosa e roxo. Ou quando a cor do branquio é  vermelho essa conclusão se dá para quando a cor do chapeu é cor de pele, vermelha, marrom, e rosa.. Quando a cor branquial for cor de pele temos que o cogumelo é venenoso.

```{r}
ggplot(mush, aes(x = cor_esporos, y = odor, col = classificacao)) + 
  geom_jitter(alpha = 0.5) + 
  scale_color_manual(breaks = c("comestivel", "venenoso"), 
                     values = c("green", "darkblue"))
```


O odor é definitivamente um preditor informativo. Basicamente,
se cheira é duvidoso, picante ou pungente, fique longe. Se cheira a anis ou amêndoa, você pode ir em frente. Se não cheira nada, você tem mais chances de ser comestível do que não. E quando a cor do esporos é preto, marrom ou branco e o odor é duvidoso, picante ou pungente tera chances de ser venenosso, e para a cor dos esporos cor de pele, chocolate, preto, marrom ou laranja e o odor é nenhum ou anis o cocumelho será comestivel.

### Analise modelo, Redução de dimensionalidade e Correlação

```{r warning=FALSE}
set.seed(2020)
#view(mush)
arvore_mod<-rpart(classificacao ~ ., data = mush)
#________________________________________________________________________________


#Faz o plot da arvore de decissão
rpart.plot(arvore_mod , extra = 104, box.palette = "YlGnBl", 
           branch.lty = 3, nn = TRUE)
```
A proposta de construçao desta arvore advém de um particionamento do banco de dados. Isto é, e utilizado 80% dos dados como um conjunto de treino, e
20% dos dados como forma de teste, afim de verificar a assertividade do modelo.

```{r warning=FALSE}

# Outra arvore de decissão
# a <- ctree(classificacao ~ ., mush)
# plot(a)

rf = randomForest(classificacao ~ .,  
                  ntree = 100,
                  data = mush)
#plot(rf)
varImpPlot(rf,  
           sort = T,
           main = "Variable Importance")
```
```{r warning=FALSE}

rf$importance[rf$importance>=145,]
```

Obtemos as importancias das variaveis ultilizando o random floreste
e escolhemos o corte de 145, onde as variaveis com importancia maior que 15 serão consideradas nos estudos dos modelos adiante, assim conseguindo fazer uma redução de dimensionalidade onde o banco com 21 variáveis exceto a variavel resposta, vemos que 7 variaveis tem grau de importancia alto. Note que no plote das variáveis "odor" e "cor_esporos" vemos que a separação de cogumelos comestivel e venenoso fica nitida e vemos que essas duas variaveis são as que apresenta maior grau de importância, note também que essas duas variáveis são as que ficaram na arvore de decissão. Note também que para o plote com a variável "formato_chapeu" tem grau de importancia muito e  notamos que não fica nitido a separação de cogumelos comestivel e venenosso.

```{r}
ggplot(mush, aes(x = tamanho_branquial, y = tipo_aneis, col = classificacao)) +
  geom_jitter(alpha = 0.5) + 
  scale_color_manual(breaks = c("comestivel", "venenoso"), 
                     values = c("green", "darkblue"))
```

Note que apois apresentar o grau de importancia das variaveis, fizemos o plote do "tipo_anel" com o "tamanho_branquial" e coloramos com base nos cocumelos comestiveis e venenossos. E vemos que essas duas variaveis são bem nitidas a separação de comestivel e venenosso, exceto para a classe "penso" no tipo_anel.



Para Analizarmos a correlações das variaveis vamos criar um subbanco com a variaveis alvo e as variaveis com grau de importancia alto, depois como o banco esta no formato de factor vamos transformar o banco em numerico para poder calcular as correlações 

```{r}
# vamos pegar as variaveis com grau de importancia alto
df<-subset(mush, select = c(1,6,9,10,13,19,20,21))

# Transformando o banco em numerico
df$classificacao<-as.integer(mapvalues(df$classificacao,c("comestivel", "venenoso"),1:2))
df$odor<-as.integer(mapvalues(df$odor, c("amendoa", "creosotose", "falta", "anis", "mofado", "nenhum", "pungente", "picante", "duvidoso"),1:9))
df$tamanho_branquial<-as.integer(mapvalues(df$tamanho_branquial, c("ampla", "limitado"),1:2))
df$cor_branquial<-as.integer(mapvalues(df$cor_branquial, c("pele", "vermelho", "cinza", "chocolate", "preto", "marrom", "laranja", "rosa", "verde", "roxo", "branco", "amarelo"),1:12))
df$superficie_caule_acima_anel<-as.integer(mapvalues(df$superficie_caule_acima_anel, c("fibroso", "sedosa", "liso", "escamosa"),1:4))
df$tipo_aneis<-as.integer(mapvalues(df$tipo_aneis, c("evanescente", "deslumbrante", "largo", "nenhum", "penso"),1:5))
df$cor_esporos<-as.integer(mapvalues(df$cor_esporos, c("pele", "chocolate", "preto", "marrom", "laranja", "verde", "roxo", "branco", "amarelo"),1:9))
df$populacao<-as.integer(mapvalues(df$populacao, c("abundante", "agrupado", "numeroso", "espalhada", "varias", "solitaria"),1:6))

# Vamos renomar as variaveis para ficar mais agradavel a saida
#tamanho_branquial = , superficie_caule_acima_anel = superf_c_a_anel
colnames(df)<-c("classificacao", "odor","tam_branquial",
                "cor_branquial", "superf_c_a_anel","tipo_aneis","cor_esporos", "populacao")

glimpse(df)

# Calculando as correlações 
M<-cor(df)

corrplot(M,type = "upper", order = "hclust", sig.level = 0.01, insig = "blank")
```



### Validação Cruzada

A seguir vamos fazer a analises com o banco de dados, fazendo validação cruzada usando k-fold igual a 10 e cv igual a 10, note que a variavel resposta é categorica e os banco de treinamento e de teste que obtemos na validação cruzada precisa ter a mesma proporssão, onde no banco original a variavel "classificação" apresenta 0.52 comestivel e 0.48 venenosso e os bancos de teste e treinamento a variavel classificação precisar ter essas mesmas proporção.   
Como estamos lidando com um problema de classificação, na validação cruzada calculamos a matriz de confussão e obtemos o seguintes indicadores Sensitivity, Specificity, Prevalence, PPV(Pos Pred Value), NPV( Neg Pred Value), Detection Rate, Detection Prevalence, Balanced Accuracy, Precision , Recall e F1.

#####
Diante de outros metodos de modelagem, a redução de dimensionalidade não foi satisfatoria, como no caso do knn, onde este precisou de 19 das 22 variaveis, para sua contrução.
#####
```{r}
### Vamos fazer a validação cruzada para as variáveis com grau de importancia alto

### Organizando o banco
mush.pronto<-subset(mush, select = c(1,3,4,5,6,8,9,10,11,12,13,14,15,16,18,19,20,21,22))

#view(mush.pronto)
# Vamos colocar 90% para o banco de treinamento e 10% para o banco de teste
K=10
cv = 10

R.modelo.arvore.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.random.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.Knn.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.SVM.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.pred.logit_mod.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.percep.k<-matrix(NA, nrow = K,ncol = 11)

set.seed(2020)
######## Interacoes K-Fold ##########
for(t in 1:K)
{
  
  R.modelo.arvore.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.random.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.Knn.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.SVM.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.pred.logit_mod.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.percep.cv<-matrix(NA, nrow = cv,ncol = 11)
  
  #group <- sample(group)
  amostra<-createDataPartition(y = mush.pronto$classificacao, times = 10, p = 0.9, list = FALSE)
  # Esta função é muito boa pois quando formos para a tarefa de classificação 
  # ele mantem a proporção das classes que é comestivel 0.52 , venenoso 0.48
  
  ######## Interacoes CrossValidation ##########

  for(i in 1:cv){
    
    ##################################################
    round(prop.table(table(mush.pronto$classificacao)), 2)
    #Variaveis temporarias Treinamento
    mush.Trein<-mush.pronto[amostra[,i],]
    print(round(prop.table(table(mush.Trein$classificacao)), 2))
    
    #Variaveis temporarias Treinamento
    mush.Test<-mush.pronto[-amostra[,i],]
    print(round(prop.table(table(mush.Trein$classificacao)), 2))
    
    
    ############ MODELOS LOGISTICO Multinomial ########
    fit.logit_mod <- multinom(classificacao ~ ., data = mush.Trein)
    pred.logit_mod<-predict(fit.logit_mod, newdata = mush.Test[,-1], type = "class")
    
    R.modelo.pred.logit_mod.cv[i,]<-confusionMatrix(data=pred.logit_mod, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    
    ############ MODELOS Arvore ########
    fit.arvore<-rpart(classificacao ~ . , data = mush.Trein)
    pred.arvore<-predict(fit.arvore, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.arvore.cv[i,]<-confusionMatrix(data=pred.arvore, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    ############ MODELOS Random florest ########
    
    fit.randon<-randomForest(classificacao ~ . , data = mush.Trein)
    pred.random<-predict(fit.randon, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.random.cv[i,]<-confusionMatrix(data=pred.random, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    
    ############ MODELOS Knn ########
    fit.knn<-knn3(classificacao ~ . , data = mush.Trein,k=6)
    pred.knn<-predict(fit.knn, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.Knn.cv[i,]<-confusionMatrix(data=pred.knn, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    
    
    ############ MODELOS SVM ########
    fit.svm<-svm(classificacao ~ . , data = mush.Trein, type='C-classification', kernel='radial')
    pred.svm<-predict(fit.svm, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.SVM.cv[i,]<-confusionMatrix(data=pred.svm, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    ########### MODELO Perceptron ########
    fit.percep<-nnet(classificacao ~ . , data = mush.Trein,size = 1)
    pred.percep<-predict(fit.percep, newdata = mush.Test[,-1], type = "class")
    pred.percep<-as.factor(pred.percep)
    #Vamos fazer a matriz de confusão
    R.modelo.percep.cv[i,]<-confusionMatrix(data=pred.percep, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
  }
  
  # Salvando os resultados do for anterior
  R.modelo.arvore.k[t,]<-colMeans(R.modelo.arvore.cv)
  R.modelo.random.k[t,]<-colMeans(R.modelo.random.cv)
  R.modelo.Knn.k[t,]<-colMeans(R.modelo.Knn.cv)
  R.modelo.SVM.k[t,]<-colMeans(R.modelo.SVM.cv)
  R.modelo.pred.logit_mod.k[t,]<-colMeans(R.modelo.pred.logit_mod.cv)
  R.modelo.percep.k[t,]<-colMeans(R.modelo.percep.cv)
  
}

R.Arvore<-colMeans(R.modelo.arvore.k)
R.Random<-colMeans(R.modelo.random.k)
R.Knn<-colMeans(R.modelo.Knn.k)
R.SVM<-colMeans(R.modelo.SVM.k)
R.Logis.Mod<-colMeans(R.modelo.pred.logit_mod.k)
R.perceptron<-colMeans(R.modelo.percep.k)

Result.Matriz<-matrix(NA,nrow = 11,ncol = 6)
Result.Matriz[,1]<-R.Arvore
Result.Matriz[,2]<-R.Random
Result.Matriz[,3]<-R.SVM
Result.Matriz[,4]<-R.Knn
Result.Matriz[,5]<-R.Logis.Mod
Result.Matriz[,6]<-R.perceptron
row.names(Result.Matriz)<-c("Sensitivity","Specificity","Pos Pred Value","Neg Pred Value",     
                           "Precision","Recall","F1","Prevalence","Detection Rate",
                           "Detection Prevalence","Balanced Accuracy")
colnames(Result.Matriz)<-c("Arvore", "Random","SVM","Knn","Logist.Mult","Perceptron")

```
```{r}
Result.Matriz

```


Apois rodar a validação cruzada para os modelos "Arvore de dercisão","Random florest","SVM","Knn","Logistica Multinomial" e "Perceptron" vemos a saida com os indicadores falados anteriormente e vemos que o modelo  "Random florest" e "Logistica Multinomial" apresenta a accuracy igual a 1. No geral todos os modelos apresentam resultados muitos bons, mais vemos que os dois melhores modelos foram  "Random florest" e "Logistica Multinomial".

#####
Fazendo a validação cruzada para as 8 variaveis que continuaram apois a redução de dimenscionalidade. Como inicialmento o modelo Knn não redou para esses dados com a redução nessa validação retiramos o modelo knn.

```{r}
### Vamos fazer a validação cruzada para as variáveis com grau de importancia alto

### Organizando o banco
mush.pronto<-subset(mush, select = c(1,6,9,10,13,19,20,21))


# Vamos colocar 90% para o banco de treinamento e 10% para o banco de teste
K=10
cv = 10

R.modelo.arvore.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.random.k<-matrix(NA, nrow = K,ncol = 11)
#R.modelo.Knn.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.SVM.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.pred.logit_mod.k<-matrix(NA, nrow = K,ncol = 11)
R.modelo.percep.k<-matrix(NA, nrow = K,ncol = 11)

set.seed(2020)
######## Interacoes K-Fold ##########
for(t in 1:K)
{
  
  R.modelo.arvore.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.random.cv<-matrix(NA, nrow = cv,ncol = 11)
  #R.modelo.Knn.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.SVM.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.pred.logit_mod.cv<-matrix(NA, nrow = cv,ncol = 11)
  R.modelo.percep.cv<-matrix(NA, nrow = cv,ncol = 11)
  
  #group <- sample(group)
  amostra<-createDataPartition(y = mush.pronto$classificacao, times = 10, p = 0.9, list = FALSE)
  # Esta função é muito boa pois quando formos para a tarefa de classificação 
  # ele mantem a proporção das classes que é comestivel 0.52 , venenoso 0.48
  
  ######## Interacoes CrossValidation ##########

  for(i in 1:cv){
    
    ##################################################
    round(prop.table(table(mush.pronto$classificacao)), 2)
    #Variaveis temporarias Treinamento
    mush.Trein<-mush.pronto[amostra[,i],]
    print(round(prop.table(table(mush.Trein$classificacao)), 2))
    
    #Variaveis temporarias Treinamento
    mush.Test<-mush.pronto[-amostra[,i],]
    print(round(prop.table(table(mush.Trein$classificacao)), 2))
    
    
    ############ MODELOS LOGISTICO Multinomial ########
    fit.logit_mod <- multinom(classificacao ~ ., data = mush.Trein)
    pred.logit_mod<-predict(fit.logit_mod, newdata = mush.Test[,-1], type = "class")
    
    R.modelo.pred.logit_mod.cv[i,]<-confusionMatrix(data=pred.logit_mod, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    
    ############ MODELOS Arvore ########
    fit.arvore<-rpart(classificacao ~ . , data = mush.Trein)
    pred.arvore<-predict(fit.arvore, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.arvore.cv[i,]<-confusionMatrix(data=pred.arvore, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    ############ MODELOS Random florest ########
    
    fit.randon<-randomForest(classificacao ~ . , data = mush.Trein)
    pred.random<-predict(fit.randon, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.random.cv[i,]<-confusionMatrix(data=pred.random, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    
    ############ MODELOS Knn ########
    #fit.knn<-knn3(classificacao ~ . , data = mush.Trein,k=6)
    #pred.knn<-predict(fit.knn, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    #R.modelo.Knn.cv[i,]<-confusionMatrix(data=pred.knn, reference = mush.Test$classificacao, positive="comestivel")$byClas
    
    ############ MODELOS SVM ########
    fit.svm<-svm(classificacao ~ . , data = mush.Trein, type='C-classification', kernel='radial')
    pred.svm<-predict(fit.svm, newdata = mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    R.modelo.SVM.cv[i,]<-confusionMatrix(data=pred.svm, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
    ########### MODELO Perceptron ########
    fit.percep<-nnet(classificacao ~ . , data = mush.Trein,size = 1)
    pred.percep<-predict(fit.percep, newdata = mush.Test[,-1], type = "class")
    pred.percep<-as.factor(pred.percep)
    #Vamos fazer a matriz de confusão
    R.modelo.percep.cv[i,]<-confusionMatrix(data=pred.percep, reference = mush.Test$classificacao, positive="comestivel")$byClass
    
  }
  
  # Salvando os resultados do for anterior
  R.modelo.arvore.k[t,]<-colMeans(R.modelo.arvore.cv)
  R.modelo.random.k[t,]<-colMeans(R.modelo.random.cv)
  #R.modelo.Knn.k[t,]<-colMeans(R.modelo.Knn.cv)
  R.modelo.SVM.k[t,]<-colMeans(R.modelo.SVM.cv)
  R.modelo.pred.logit_mod.k[t,]<-colMeans(R.modelo.pred.logit_mod.cv)
  R.modelo.percep.k[t,]<-colMeans(R.modelo.percep.cv)
  
}

R.Arvore<-colMeans(R.modelo.arvore.k)
R.Random<-colMeans(R.modelo.random.k)
#R.Knn<-colMeans(R.modelo.Knn.k)
R.SVM<-colMeans(R.modelo.SVM.k)
R.Logis.Mod<-colMeans(R.modelo.pred.logit_mod.k)
R.perceptron<-colMeans(R.modelo.percep.k)

Result.Matriz<-matrix(NA,nrow = 11,ncol = 6)
Result.Matriz[,1]<-R.Arvore
Result.Matriz[,2]<-R.Random
Result.Matriz[,3]<-R.SVM
#Result.Matriz[,4]<-R.Knn
Result.Matriz[,5]<-R.Logis.Mod
Result.Matriz[,6]<-R.perceptron
row.names(Result.Matriz)<-c("Sensitivity","Specificity","Pos Pred Value","Neg Pred Value",     
                           "Precision","Recall","F1","Prevalence","Detection Rate",
                           "Detection Prevalence","Balanced Accuracy")
colnames(Result.Matriz)<-c("Arvore", "Random","SVM","Knn","Logist.Mult","Perceptron")

```
```{r}
Result.Matriz

```


### Rodando os modelos para todos os dados

Vamos separar o banco de dados em 80% em dados de treinamento e 20% em dados de teste e vamos verificar a matiz de confussão para esses modelos estudados.



```{r}

# Vamos fazer uma amostra com 80% para o banco de treinamento e 20% para banco de Test
set.seed(2020)

  amostra<-createDataPartition(y = mush$classificacao, times = 1, p = 0.8, list = FALSE)

##################################################
    #Variaveis temporarias Treinamento
    Mush.Trein<-mush[amostra[,1],]
    
    #Variaveis temporarias Treinamento
    Mush.Test<-mush[-amostra[,1],]
    
    ############ MODELOS LOGISTICO Multinomial ########
    fit.logit_mod <- multinom(classificacao ~ ., data = Mush.Trein)
    pred.logit_mod<-predict(fit.logit_mod, newdata = Mush.Test[,-1], type = "class")
    
    confusionMatrix(data=pred.logit_mod, reference = Mush.Test$classificacao, positive="comestivel")
    
    
    ############ MODELOS Arvore ########
    fit.arvore<-rpart(classificacao ~ . , data = Mush.Trein)
    pred.arvore<-predict(fit.arvore, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.arvore, reference = Mush.Test$classificacao, positive="comestivel")
    
    ############ MODELOS Random florest ########
    
    fit.randon<-randomForest(classificacao ~ . , data = Mush.Trein)
    pred.random<-predict(fit.randon, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.random, reference = Mush.Test$classificacao, positive="comestivel")
    
    
    ############ MODELOS Knn ########
    fit.knn<-knn3(classificacao ~ . , data = Mush.Trein,k=6)
    pred.knn<-predict(fit.knn, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.knn, reference = Mush.Test$classificacao, positive="comestivel")
    

    ############ MODELOS SVM ########
    fit.svm<-svm(classificacao ~ . , data = Mush.Trein, type='C-classification', kernel='radial')
    pred.svm<-predict(fit.svm, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.svm, reference = Mush.Test$classificacao, positive="comestivel")
    
    ########### MODELO Perceptron ########
    fit.percep<-nnet(classificacao ~ . , data = Mush.Trein,size = 1)
    pred.percep<-predict(fit.percep, newdata = Mush.Test[,-1], type = "class")
    pred.percep<-as.factor(pred.percep)
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.percep, reference = Mush.Test$classificacao, positive="comestivel")
    

```


### Rodando os modelos para os dados apois a redução

Vamos separar o banco de dados em 80% em dados de treinamento e 20% em dados de teste e vamos verificar a matiz de confussão para esses modelos estudados.

#### Nesse não estamos considerando todas as variaveis

```{r}

### Organizando o banco
Mush.P<-subset(mush, select = c(1,6,9,10,13,19,20,21))

# Vamos fazer uma amostra com 80% para o banco de treinamento e 20% para banco de Test
set.seed(2020)

  amostra<-createDataPartition(y = Mush.P$classificacao, times = 1, p = 0.8, list = FALSE)

##################################################
    #Variaveis temporarias Treinamento
    Mush.Trein<-Mush.P[amostra[,1],]
    
    #Variaveis temporarias Treinamento
    Mush.Test<-Mush.P[-amostra[,1],]
    
    ############ MODELOS LOGISTICO Multinomial ########
    fit.logit_mod <- multinom(classificacao ~ ., data = Mush.Trein)
    pred.logit_mod<-predict(fit.logit_mod, newdata = Mush.Test[,-1], type = "class")
    
    confusionMatrix(data=pred.logit_mod, reference = Mush.Test$classificacao, positive="comestivel")
    
    
    ############ MODELOS Arvore ########
    fit.arvore<-rpart(classificacao ~ . , data = Mush.Trein)
    pred.arvore<-predict(fit.arvore, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.arvore, reference = Mush.Test$classificacao, positive="comestivel")
    
    ############ MODELOS Random florest ########
    
    fit.randon<-randomForest(classificacao ~ . , data = Mush.Trein)
    pred.random<-predict(fit.randon, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.random, reference = Mush.Test$classificacao, positive="comestivel")
    
    
    ############ MODELOS Knn ########
    #fit.knn<-knn3(classificacao ~ . , data = Mush.Trein,k=6)
    #pred.knn<-predict(fit.knn, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    #confusionMatrix(data=pred.knn, reference = Mush.Test$classificacao, positive="comestivel")
    

    ############ MODELOS SVM ########
    fit.svm<-svm(classificacao ~ . , data = Mush.Trein, type='C-classification', kernel='radial')
    pred.svm<-predict(fit.svm, newdata = Mush.Test[,-1], type = "class")
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.svm, reference = Mush.Test$classificacao, positive="comestivel")
    
    ########### MODELO Perceptron ########
    fit.percep<-nnet(classificacao ~ . , data = Mush.Trein,size = 1)
    pred.percep<-predict(fit.percep, newdata = Mush.Test[,-1], type = "class")
    pred.percep<-as.factor(pred.percep)
    #Vamos fazer a matriz de confusão
    confusionMatrix(data=pred.percep, reference = Mush.Test$classificacao, positive="comestivel")
    

```


